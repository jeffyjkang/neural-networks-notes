{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d5a0537-0683-46ff-a083-05450a8f56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from keras import models, layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b48d593-b7e5-4862-9441-55b8c93242dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features array shape: (10000, 50)\n",
      "Target array length: 10000\n"
     ]
    }
   ],
   "source": [
    "# define the number of features\n",
    "num_features = 50\n",
    "\n",
    "# generate features matrix and target vector, binary classification (two classes)\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                       n_features = num_features,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       weights = [.5, .5],\n",
    "                                       random_state = 42)\n",
    "\n",
    "# verify the size of the features and target\n",
    "print('Features array shape:', features.shape)\n",
    "print('Target array length:', len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0c53b3-5f72-4dcb-b97f-235eeb5741e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to return a compiled network\n",
    "def make_network(optimizer='adam'):\n",
    "    # instantiate a sequential model\n",
    "    network = models.Sequential()\n",
    "    # add an input layer (shape = number of features)\n",
    "    network.add(layers.Dense(units=8, activation='relu', input_shape=(num_features,)))\n",
    "    # add hidden layer with 8 neurons\n",
    "    network.add(layers.Dense(units=8, activation='relu'))\n",
    "    # add output layer with sigmoid activation func\n",
    "    network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    network.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    # return compiled network\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9702d4-59ed-46ba-bf09-8cb3de5b453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/07vgg77n2vd0vy3wf99ryrmh0000gn/T/ipykernel_16604/2594605819.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  neural_network = KerasClassifier(build_fn=make_network, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "neural_network = KerasClassifier(build_fn=make_network, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476dc8dd-7b45-4a88-aed1-c321228b1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter space over which to search\n",
    " = [10, 25]\n",
    "batches = [4, 8, 32]\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "\n",
    "# make a dictionary of the parameters\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "\n",
    "# create and fit the grid search\n",
    "grid = GridSearchCV(estimator=neural_network, cv=5, param_grid=hyperparameters)\n",
    "grid_result = grid.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75edbdd3-d96d-4339-8da7-ce654f7abd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 4, 'epochs': 25, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at best params\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ae330cd-7c6c-485a-bbe8-b9dcaf39cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of features\n",
    "num_features = 50\n",
    "\n",
    "# generate features matrix and target vector, binary classification (two classes)\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                       n_features = num_features,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       random_state = 42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "754ea6d3-8fd6-4bfa-860d-59eb74f68748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dbc8d6a-cf44-40eb-83dc-308acef44628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters and values\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8, 16]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "# eval the model using accuracy\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# write the func to creat the logs\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuarcy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71143bbb-0e40-48ad-b0a3-f6f88aa172b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the func to create the model with the specified hyperparameter tuning\n",
    "def train_test_model(hparams):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # run with 1 epoch to speed things up for demo\n",
    "    model.fit(X_train, y_train, epochs=1)\n",
    "    _, accuracy = model.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0039ed1b-811e-4e5c-aa0f-dfd0f6baa8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams) # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce78088b-436e-4184-8a3d-af8078488517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- starting trial: run-0\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 0s 616us/step - loss: 2.1547 - accuracy: 0.2916\n",
      "79/79 [==============================] - 0s 541us/step - loss: 1.3244 - accuracy: 0.7136\n",
      "--- starting trial: run-1\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 0s 631us/step - loss: 1.5321 - accuracy: 0.4913\n",
      "79/79 [==============================] - 0s 571us/step - loss: 0.8655 - accuracy: 0.7324\n",
      "--- starting trial: run-2\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 0s 672us/step - loss: 1.7390 - accuracy: 0.4301\n",
      "79/79 [==============================] - 0s 568us/step - loss: 0.9749 - accuracy: 0.7372\n",
      "--- starting trial: run-3\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 0s 659us/step - loss: 1.7068 - accuracy: 0.4308\n",
      "79/79 [==============================] - 0s 559us/step - loss: 0.9519 - accuracy: 0.7180\n",
      "--- starting trial: run-4\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 0s 700us/step - loss: 1.4953 - accuracy: 0.4613\n",
      "79/79 [==============================] - 0s 576us/step - loss: 0.7584 - accuracy: 0.7120\n",
      "--- starting trial: run-5\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 0s 622us/step - loss: 1.3221 - accuracy: 0.5388\n",
      "79/79 [==============================] - 0s 565us/step - loss: 0.7167 - accuracy: 0.7384\n",
      "--- starting trial: run-6\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "235/235 [==============================] - 0s 750us/step - loss: 1.5989 - accuracy: 0.4585\n",
      "79/79 [==============================] - 0s 555us/step - loss: 0.8065 - accuracy: 0.6956\n",
      "--- starting trial: run-7\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "235/235 [==============================] - 0s 672us/step - loss: 1.4178 - accuracy: 0.5677\n",
      "79/79 [==============================] - 0s 573us/step - loss: 0.7371 - accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer\n",
    "            }\n",
    "            run_name = 'run-%d' % session_num\n",
    "            print('--- starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54b599b1-0e1a-4012-bfa0-9d38a2d355e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77c229-410a-4e69-98ed-dba6d13e56a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
